% \VignetteIndexEntry{hapmap100k Vignette}
% \VignetteKeywords{copy number, genotype, SNP}
% \VignettePackage{VanillaICE}
\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}

\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rfunction}[1]{\texttt{#1}}
\newcommand{\Robject}[1]{\texttt{#1}}
\newcommand{\R}{\textsf{R}}

\newcommand{\cne}{\widehat{\text{CN}}}
\newcommand{\gte}{\widehat{\text{GT}}}
\newcommand{\gtehom}{\widehat{\text{HOM}}}
\newcommand{\gtehet}{\widehat{\text{HET}}}
\newcommand{\pgte}{\text{S}_{\widehat{\text{\tiny GT}}}}
\newcommand{\pcne}{\text{S}_{\widehat{\text{\tiny CN}}}}
\newcommand{\pgtehom}{\text{S}_{\widehat{\text{\tiny HOM}}}}
\newcommand{\pgtehet}{\text{S}_{\widehat{\text{\tiny HET}}}}
\newcommand{\thom}{\text{HOM}}
\newcommand{\thet}{\text{HET}}
\newcommand{\bDelta}{\mbox{\boldmath $\Delta$}}
\newcommand{\real}{\mbox{$\mathbb R$}}      % real numbers
\newcommand{\bnu}{\mbox{\boldmath $\nu$}}
\newcommand{\ice}{\Rpackage{VanillaICE}}

\textwidth=6.2in
\textheight=8.5in
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

\begin{document}
\title{Processing 100k Hapmap samples: \Rpackage{oligo} \longarrow \Rpackage{VanillaICE}}
\author{Robert Scharpf and Ingo Ruczinski}
\maketitle

<<setup, echo=FALSE, results=hide>>=
options(width=69)
@ 

\section{Introduction}

The objective of this vignette is to start from a fairly large batch
of unprocessed CEL files, process the CEL files using
\Rpackage{oligo}, and smooth the data to identify chromosomal
alterations using the \Rpackage{VanillaICE}.  We will keep track of
bottlenecks in computation and memory size and work.  While this
vignette is focused on the Affymetrix 100k platform, corresponding
vignettes for other Affymetrix and Illumina platforms will be posted
in the near future.  Warning: this vignette illustrates a work flow
for handling a large set of CEL files -- the code here is not
reproducible because the files used in this example are not provided
as part of the \Rpackage{VanillaICE} package.

Perhaps a figure here showing the relationship of classes that we will
be generating.

\section{Preprocessing CEL files with \Rpackage{oligo}}

<<packages>>=
library(oligo)
library(VanillaICE)
library(pd.genomewidesnp.6)
@

%\Rpackage{oligo} presently does not support '.gz' files, so the first
%thing I'm doing is copying all the unprocessed zipped (*CEL.gz) to a
%local temporary directory.
From node 31,

<<tmpDirectory>>=
pathToCel <- "/nexsan/bst2/microarray/SNP/GenomeWideByAffy/cel/GenomeWideSNP_6/hapmap"
if(!file.exists(pathToCel)) stop("directory does not exist")
setwd(pathToCel)
pathTo <- "/tmp/rsHapmapAffy6"
##if(!file.exists(pathTo)){
##	dir.create(pathTo)
##}
@ 

Here we load a \Robject{data.frame} containing phenotypic information
on the samples.

<<phenoData, eval=TRUE>>=
pathTesting <- system.file("testing", package="VanillaICE")
load(paste(pathTesting, "hapmapTable.rda", sep="/"))
str(hapmapTable)
@ 

(The 00README.txt file in the same directory has additional
information about the covariates).  We will now create an object of
class \Robject{AnnotatedDataFrame} as a container for the sample
characteristics.  This information will be passed to the
\Robject{crlmm} function during preprocessing.  In particular, the
covariate 'gender' is useful and the vocabulary for this is
controlled. AFAIK, gender = 1 for male and 2 for female is always
required.

<<eval=TRUE>>=
celfiles <- list.celfiles()
createHapmapInfo <- function(files, point){
	ids <- sapply(strsplit(files, "\\."), function(x) x[point])
	ids <- sapply(strsplit(ids, "_"), function(x) x[point])
	idx <- match(ids, hapmapTable$hapmap)
	hapmapTable[idx, ]
}
pd <- createHapmapInfo(celfiles,1)
colnames(pd)[5] <- "gender"
pd <- as(pd, "AnnotatedDataFrame")
varMetadata(pd)$labelDescription <- c("family pedigree id (empty for unrelated)",
				      "individual pedigree id (always 1 for unrelateds)",
				      "father pedigree id (0 if founder)",
				      "mother pedID (0 if founder)",
				      "sex (1=male, 2=female",
				      "individual LSID (assigned by DCC)",
				      "sample LSID (assigned by DCC based on Coriell catalog IDs)",
				      "cel file names")
@ 

I am going to make the set of files analyzed slightly smaller by only
considering the samples that are independent--those with founder id
(fid) value of zero.

<<independentSamples, eval=TRUE>>=
which <- pd$fid == 0
pd <- pd[which, ]
celfiles <- celfiles[which]
sampleNames(pd) <- pd$hapmap
fullFilenames <- file.path(getwd(), celfiles)
@ 

Now we use the function \Robject{justCRLMM} to preprocess.  This
function returns an object of class \Robject{SnpCallSetPlus}. In
addition to genotype calls, \Robject{SnpCallSetPlus} contains
summaries of the intensities for the A and B alleles on both the sense
and antisense strands.  We will later demonstrate a quick way to get a
first approximation of copy number using these intensities.

<<justCrlmmPartial, eval=FALSE, echo=FALSE>>=
fullFilenames <- fullFilenames[1:3]
pd <- pd[1:3, ]
@ 

In the devel version of \Rpackage{oligo}, several intermediate files are produced from
the \Robject{crlmm} function and nothing is returned.

<<crlmm, eval=TRUE>>=
stopifnot(all(sapply(fullFilenames, file.exists)))
outdir <- file.path(pathTo, "tmp")
if(file.exists(outdir)){
	unlink(outdir, recursive=TRUE)
}


crlmm(fullFilenames, outdir=outdir) #phenoData=pd, verbose=FALSE)
calls.file <- file.path(outdir, "crlmm-calls.txt")
conf.file <- file.path(outdir, "crlmm-conf.txt")
calls <- as(read.delim(calls.file), "matrix")
conf <- as(read.delim(conf.file), "matrix")
alleleA <- readSummaries("alleleA", outdir)##[1:5,]
alleleB <- readSummaries("alleleB", outdir)

##Save by chromosome or by sample?  Might be easiest (downstream) to save by sample.
callsetplus <- new("SnpCnvCallSetPlus",
		   calls=calls,
		   callsConfidence=conf,
		   thetaA=alleleA,
		   thetaB=alleleB,
		   phenoData=pd)
callset <- strsplit(callsetplus, sampleNames(callsetplus))
for(i in 1:length(callset)){
	
}


save(callsetplus, file=file.path(pathTo, "callsetplus.rda"), compress=TRUE)
@ 

<<clean, eval=TRUE>>=
unlink(outdir, recursive=TRUE)
@ 

<<eval=FALSE>>=

##Get position of all probes (polymorphic + nonpolymorphic)
##Get copy number for polymorphic probes.  What to use for nonpolymorphic probes?
@ 

Read in the intermediate files and create an object of class
\Robject{SnpCnvCallSetPlus}.

\section{SNP-level summaries}

\subsection{Combining platforms}

A summary of the \Robject{SnpCallSetPlus} instance:

<<snpCallSetPlus, eval=FALSE>>=
callsetplus
@ 

Note that a column \Robject{crlmmSNR} has been added to the
\Robject{phenoData}:

<<varlabels, eval=FALSE>>=
varLabels(callsetplus)
@ 

The \Robject{crlmmSNR} covariate is a signal to noise ratio and
summarizes the overall quality of the samples.  If the SNR ratio is $<
3$, we recommend excluding the sample from downstream analyses.

<<exclusions, eval=FALSE>>=
callset <- callsetplus[, callsetplus$crlmmSNR > 3]
@ 

At least for the 100k platform, the speed of all of the following
computations is increased if we pass the chromosome and physical
position along with the SNP object.  One may do this by storing this
information in the \Robject{featureData} slot:

<<addFd, eval=FALSE>>=
featureData(callset)$chromosome <- chromosome(callset)
featureData(callset)$position <- position(callset)
@ 

<<eval=FALSE, echo=FALSE>>=
save(callset, file=paste(pathTo, "callset.rda", sep="/"), compress=TRUE)
@ 

<<echo=FALSE, eval=FALSE>>=
load(paste(pathTo, "callset.rda", sep="/"))
@ 

\subsection{Estimating copy number}

We expect that the averaged intensities for the A and B alleles will
be proportional to the total copy number.  Because the fluorescence at
a SNP is very much SNP-dependent, we'll center each SNP at the median
value and then recenter at the 'normal' copy number.  Here, we define
normal copy number to be two for autosomes, one for the male X, and
two for the female X. Because we've noticed that homozygous genotype
calls appear to have overall less fluorescence than the heterozygous
genotype calls, we'll center the homozygous and heterozygous genotype
calls at their respective medians.

<<A, eval=FALSE>>=
log2cn <- getA(callset)
dim(log2cn)
@ 

%We then average the sense and antisense values:

%<<avgA, eval=FALSE>>=
%log2cn <- rowMeans(A, dims=2, na.rm=TRUE)
%dim(log2cn)
%@ 

We center the homozygous and heterozygous genotypes separately (since
the average intensities differs by call):

<<centerByGenotype, eval=FALSE>>=
chr.matrix <- matrix(chromosome(callset), ncol=ncol(log2cn), nrow=nrow(log2cn))
median.hom <- median(log2cn[(calls(callset) == 1 | calls(callset) == 3) & chr.matrix != "X"], na.rm=TRUE)
median.het <- median(log2cn[calls(callset) == 2 & chr.matrix != "X"], na.rm=TRUE)
recenterByGenotype <- function(x, callset, recenter.hom, recenter.het){
	calls <- as.vector(calls(callset))
	x[calls == 1 | calls == 3] <- x[calls ==1 | calls == 3] - recenter.hom
	x[calls == 2] <- x[calls == 2] - recenter.het
	x
}
for(j in 1:ncol(log2cn)){
	log2cn[, j] <- recenterByGenotype(log2cn[, j], callset[, j], recenter.hom=median.hom, recenter.het=median.het)
}
@ 

Next, we sweep out a robust estimate of the median from the samples
(tries to put fluorescence intensities on a similar scale for each of
the samples)

<<bySample, eval=FALSE>>=
f <- function(x, chromosome){
	tmp2 <- split(x, chromosome)
	if(length(tmp2) > 15){
		idx <- order(sapply(tmp2, "median"))
		tmp2 <- tmp2[idx]
		tmp3 <- tmp2[-c(1:5, (length(tmp2)-4):length(tmp2))]
		med <- median(unlist(tmp3))
	} else {
		med <- median(sapply(tmp2, "median"))
	}
	return(med)
}
robust.median <- apply(log2cn, 2, f, chromosome(callset))
log2cn <- sweep(log2cn, 2, robust.median)
@ 

Next, we sweep out the SNP-specific median intensities and recenter
(centering depends on chromosome):

<<sweepMedian, eval=FALSE>>=
rowSweep <- function(callset, X, value, recenter, j){
	if(length(value) == 1){
		i <- chromosome(callset) == value
	} else {
		i <- chromosome(callset) %in% value
	}
	i[is.na(i)] <- FALSE
	if(sum(i) > 1){
		if(!missing(j)){
			if(sum(j) < 5) warning("very few samples for calculating a robust average")
			avg <- rowMedians(X[i, j], na.rm=TRUE)
			X[i, j] <- sweep(X[i, j], 1, avg) + recenter
		} else{
			avg <- rowMedians(X[i, ], na.rm=TRUE)
			X[i, ] <- sweep(X[i, ], 1, avg) + recenter
		}
	}
	X
}
if(!("gender" %in% varLabels(callset)) & any(chromosome(callset) %in% c("X", "Y", "XY"))){
	stop("gender must be specified")
}
male <- callset$gender == 1
female <- callset$gender == 2
chromosome(callset)[is.na(chromosome(callset))] <- "NA"		  
log2cn <- rowSweep(callset, log2cn,  "NA", log2(2))
log2cn <- rowSweep(callset, log2cn,  "M", log2(2))		  
log2cn <- rowSweep(callset, log2cn,  "X", log2(1), male)
log2cn <- rowSweep(callset, log2cn,  "X", log2(2), female)
log2cn <- rowSweep(callset, log2cn,  "Y", log2(1), male)
log2cn <- rowSweep(callset, log2cn,  "Y", log2(0.5), female)		  
log2cn <- rowSweep(callset, log2cn,  as.character(1:22), log2(2))
chromosome(callset)[chromosome(callset) == "NA"] <- NA
copyNumber <- 2^log2cn
@ 

The preceding codechunks may be replaced by the function
\Robject{calculateCopyNumber}.

<<calculateCopyNumber, eval=FALSE>>=
system.time(cn <- calculateCopyNumber(callset, 
				      center.autosomes=2,
				      center.X.male=1,
				      center.X.female=2,
				      center.Y.male=1,
				      center.Y.female=0.4))
identical(cn, copyNumber)
@ 

<<echo=FALSE, results=hide, eval=FALSE>>=
rm(cn); gc()
@ 
			  
We may now create an object of class \Robject{oligoSnpSet} that
contains \Robject{assayData} elements for SNP-level summaries of
genotype calls and copy number.  For now, we will assign a matrix of
missing values for copy number confidence estimates.

<<createSnpSet, eval=FALSE>>=
cnConfidence <- matrix(NA, nrow=nrow(callset), ncol=ncol(callset))
rownames(cnConfidence) <- featureNames(callset)
colnames(cnConfidence) <- sampleNames(callset)
if(identical(rownames(copyNumber), featureNames(callset))){
	snpset <- new("oligoSnpSet",
		      copyNumber=copyNumber,
		      cnConfidence=cnConfidence,
		      calls=calls(callset),
		      callsConfidence=callsConfidence(callset),
		      experimentData=experimentData(callset),
		      featureData=featureData(callset),
		      phenoData=phenoData(callset),
		      annotation=annotation(callset))
}
@ 

<<echo=FALSE, results=hide>>=
rm(cnConfidence); gc()
@ 

Estimating copy number from a \Robject{SnpCallSetPlus} object and
creating an instance of the class \Robject{oligoSnpSet} are
encapsulated in the method for coercing an object between the two
classes:

<<coerce, eval=FALSE>>=
snpset <- as(callset, "oligoSnpSet")
@ 

<<echo=FALSE, results=hide, eval=FALSE>>=
rm(callset); gc()
@ 


\section{\Rpackage{VanillaICE}: Identifying chromosomal alterations}

\subsection{Confidence estimates for copy number}

In this section we describe how one may fit a hidden Markov model
(HMM) to the SNP-level summaries provided in the \Robject{oligoSnpSet}
object.  Because it makes sense to incorporate a SNP-specific estimate
of the copy number standard error in the HMM, we do so.

For now, we drop the sex chromosomes, though hopefully it will become
clear how one could easily reset the parameters of the HMM to identify
chromosomal alterations on the sex chromosomes. We also exclude SNPs
that have missing values for chromosome.

<<excludeX, eval=FALSE>>=
snpset <- snpset[chromosome(snpset) != "X", ]
snpset <- snpset[chromosome(snpset) != "Y", ]
snpset <- snpset[!is.na(chromosome(snpset)), ]
@ 

For reasonable sample sizes ($> 20$ samples), one may calculate a
robust estimate of the copy number standard error as the product of
the within-chip and across-chip standard deviations. Note that we
scale the across-chip standard deviation by the median across chip
standard deviation.

<<robustSE, eval=FALSE>>=
calculateCnSE <- function(object,
                          referenceSet,
                          epsilon=0.1){
  if(missing(referenceSet)) stop("Require a referenceSet for estimating SNP-specific across sample variation in copy number estimates")
  require(genefilter) || stop("genefilter not available")
  is.autosome <- chromosome(object) %in% as.character(1:22) 
  object <- object[is.autosome, ]  
  referenceSet <- referenceSet[match(featureNames(object), featureNames(referenceSet)), ]
  robustSD <- function(X){
	  diff(quantile(X, probs=c(0.16, (1-0.16)), na.rm=TRUE))/2 
  }
  within.sd <- apply(copyNumber(object), 2, robustSD)
  across.sd <- apply(copyNumber(referenceSet), 1, robustSD)
  across.sd <- matrix(across.sd, nrow=nrow(object), ncol=ncol(object), byrow=FALSE)
  ##scale across.sd by the median sd of the sample
  median.across.sd <- median(across.sd)
  std.across.sd <- across.sd/median.across.sd
  SE <- within.sd*std.across.sd
  SE[SE == 0] <- epsilon
  rownames(SE) <- featureNames(object)
  SE
}
@ 

Because we will fit the HMM to the $\log2$ copy number, we will make
the appropriate transformation, compute the standard errors, and
reassign the inverse of the standard errors to the
\Robject{cnConfidence} slot of the \Robject{oligoSnpSet} object.

<<cnSe, eval=FALSE>>=
cn.se <- calculateCnSE(snpset)
if(identical(rownames(cn.se), featureNames(snpset))){
	cnConfidence(snpset) <- 1/cn.se
} else {
	stop("Rownames are not identical")
}
@ 

Here we save a \Robject{sample.snpset} object that is used in the \Rpackage{SNPchip} vignette.

<<sample.snpset>>=
sample.snpset <- snpset[sample(1:nrow(sample.snpset), 40000), 1:4]
@ 

<<echo=FALSE>>=
save(sample.snpset, file="~/madman/Rpacks/SNPchip/data/sample.snpset.RData", compress=TRUE)
notes(sample.snpset) <- "This R object was created using the hapmap100k vignette in the R package VanillaICE. Look in the inst/testing subdirectory of VanillaICE for additional details"
@ 


\section{Fitting the ICE HMM}

We instantiate an object of class \Robject{HmmParameter}, first
providing a standard order for the chromosomes and ordering the SNPs
by physical position within each chromosome:

<<echo=FALSE, eval=FALSE>>=
load("~/projects/sandbox/presentations/2008/aha/snpset.rda")
@ 

<<hmmParams, eval=FALSE>>=
chrom <- chromosome2numeric(chromosome(snpset))
snpset <- snpset[order(chrom, position(snpset)), ]
##save(snpset, file="~/projects/sandbox/presentations/2008/aha/snpset.rda", compress=TRUE)
rm(chrom); gc()
params <- new("HmmParameter",
	      snpset,
	      states=c("homD", "hemD", "N", "L", "A"),
	      cn.location=c(0.4, 1, 2, 2, 3),
	      gte.state=c(0.99, 0.99, 0.8, 0.99, 0.8),
	      cn.ICE=TRUE,
	      gt.ICE=FALSE)
@ 

FIXME: the initialization method for HmmParameter and HmmOptions is
tricky.  Need to make this more straightforward.  Also, there are not
enough checks in place to ensure that the choice of cn.location is
reasonable for the data, nor do we check that the confidence slots are
correctly specified when cn.ICE or gt.ICE is TRUE.  Need to provide
informative warning messages.  One idea is to always require copy
number to be positive -- then we could easily check for negative
values when we need a log transformation.

Arguments to the initialization method include the
\Robject{oligoSnpSet} object, the names for the hidden states, the
corresponding mean copy number for these states, and the proportion of
homozygous genotype calls expected in these states. Optionally, one
may indicate whether the HMM should incorporate confidence scores for
the copy number and genotype estimates by setting \Robject{cn.ICE} and
\Robject{gt.ICE}, respectively, to TRUE.

We may then fit the HMM

<<fitHmm, eval=FALSE>>=
system.time(fit.hapmap <- hmm(params, snpset))
##breakpoints(fit.hapmap) <- calculateBreakpoints(fit.hapmap)
@ 

<<echo=FALSE, eval=FALSE>>=
save(fit.hapmap, file="~/madman/Rpacks/VanillaICE/inst/testing/fit.hapmap100k.rda", compress=TRUE)
@ 

<<echo=FALSE, eval=FALSE>>=
load("fit.hapmap.rda")
load("snpset.rda")
if(!identical(featureNames(snpset), featureNames(fit.hapmap))){
	idx <- match(featureNames(fit.hapmap), featureNames(snpset))
	snpset <- snpset[idx,]	
}
@ 

Summary statistics for the breakpoints by chromosome
<<summarizeBreaks,eval=FALSE>>=
tab <- summary(fit.hapmap)
tab[[1]]
@ 

\section{Visualizing results}

Transform the prediction matrix to 1's (altered) and 0's (normal)

<<eval=FALSE>>=
altered <- predictions(fit.hapmap)
altered[altered == 3] <- 0
altered[altered != 0] <- 1
##Prop of SNPs in an altered state for each sample (x-axis is samples).
p <- colSums(altered)/nrow(altered)
N <- length(p)
x <- 1:N
@ 

Here we plot the proportion of SNPs in an altered state for each sample.

<<pSnp, fig=TRUE, eval=FALSE>>=
par(las=1)
plot(c(x, rev(x)), c(rev(p), rep(0, N)), 
     col="grey70", type="l", xaxt="n", xlab="Samples", bty="o", 
     lwd=2, ylab="p", xaxs="i")
polygon(c(x, rev(x)), 
	c(rev(p), rep(0, N)),
	col="grey70")
@ 

Alternatively, we may calculate the number of samples for which each
SNP is in an altered state 

<<eval=FALSE>>=
p <- rowSums(altered)
N <- length(p)
x <- 1:N
@ 

Plotting methods at this level could stand improvement
<<pSample, fig=TRUE,eval=FALSE>>=
par(las=1)
plot(c(x, rev(x)), c(rev(p), rep(0, N)), 
     col="grey70", type="l", #xaxt="n",
     ylab="p", bty="o", 
     lwd=2, xlab="all SNPs", xaxs="i")
polygon(c(x, rev(x)), 
	c(rev(p), rep(0, N)),
	col="grey70")
@ 


<<echo=FALSE,eval=FALSE>>=
##Same as previous, but by chromosome and use physical position for x-axis
p.chr <- split(p, chromosome(fit.hapmap))
x <- split(position(fit.hapmap)/1e6, chromosome(fit.hapmap))
chrom <- as.list(names(p.chr))
myplot <- function(p, x, chromosome){
	xlim <- c(0, max(x))
	N <- length(x)
	par(las=1)
	plot(c(x, rev(x)), c(rev(p), rep(0, N)), 
	     col="grey70", type="l", #xaxt="n",
	     ylab="p", bty="o", 
	     lwd=2, xlab="SNPs", xaxs="i",
	     main=paste("Chr ", chromosome), xlim=xlim)
	polygon(c(x, rev(x)), 
		c(rev(p), rep(0, N)),
		col="grey70", xlim=(xlim*1e6),
		lwd=0.8, border="grey70")
	plotCytoband(chromosome, xaxs="i")
}
par(mar=rep(2,4), oma=rep(1,4))
layout(mat=matrix(1:2, ncol=1), heights=c(1, 0.2))
myplot(p.chr[[1]], x[[1]], chrom[[1]])
@ 


The following makes a nice image of the data, but the graphic in .eps
format is too large, and so is currently not evaluated.

<<eval=FALSE>>=
chr1 <- fit.hapmap[chromosome(fit.hapmap) == "1", ]
pred <- predictions(chr1)
pred[pred != 3] <- 1
pred[pred == 3] <- 0
col <- c("white", "royalblue")
par(oma=c(5, 5, 4, 4)*.5, las=1, mar=c(3, 0, 0.5, 0.2))
layout(matrix(1:3, 3, 1),  heights=c(1, 0.3, 0.2/3))
image(position(chr1),
      y=1:209, z=pred, xaxt="n", xlab="Mb", ylab="sample",
      col=col, xaxs="i", yaxs="r", yaxt="n", bty="n")
legend("topleft", bty="n", col=col, legend=c("Normal", "Altered"), fill=col)
mtext("samples", 2, outer=TRUE, las=3, line=3, padj=0)
mtext("Chr 1", 3, outer=TRUE, cex=1.3)
at <- pretty(position(chr1))
axis(1, at=at, labels=at/1e6, cex.axis=1, las=1, cex=1.1)
freq <- rowSums(pred)
plot(position(chr1), freq, type="l", xaxt="n", xlab="Mb", bty="n", lwd=2, col="white", ylab="frequency", xaxs="i")
polygon(c(position(chr1), rev(position(chr1))), c(rep(0, length(freq)), rev(freq)), col=col[2])
par(mar=c(0, 0, 0, 0.2))
plotCytoband("1", xaxs="i", label.cytoband=FALSE)
@ 

\end{document}
